{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:27:17.205585Z",
     "start_time": "2021-10-29T13:27:17.189508Z"
    }
   },
   "outputs": [],
   "source": [
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score,accuracy_score, precision_score, recall_score, classification_report, roc_auc_score\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "    ### a 4-layer convolutional model applied to the melspectrogram. The prediction is for the central frame for a period of 3 seconds. Each frame is joined with 46 (1.5 seconds) frames before and after to add context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:27:37.801715Z",
     "start_time": "2021-10-29T13:27:37.780765Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# VAD model\n",
    "class Conv_2d(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, shape=3, stride=1, pooling=2):\n",
    "        super(Conv_2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(input_channels, output_channels, shape, stride=stride, padding=shape//2)\n",
    "        self.bn = nn.BatchNorm2d(output_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.mp = nn.MaxPool2d(pooling)\n",
    "    def forward(self, x):\n",
    "        out = self.mp(self.relu(self.bn(self.conv(x))))\n",
    "        #out = self.mp(self.relu(self.conv(x)))\n",
    "        return out\n",
    "\n",
    "class VAD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAD, self).__init__()\n",
    "        self.a_norming = nn.BatchNorm2d(1) \n",
    "        self.to_db = torchaudio.transforms.AmplitudeToDB() \n",
    "\n",
    "        self.conv1 = Conv_2d(1,32)\n",
    "        self.conv2 = Conv_2d(32,64)\n",
    "        self.conv3 = Conv_2d(64,128)\n",
    "        self.conv4 = Conv_2d(128,256)\n",
    "        \n",
    "        self.a_fc1 =  nn.Linear(10240, 512)\n",
    "        self.a_fc2 = nn.Linear(512, 256)\n",
    "        self.a_fc3 = nn.Linear(256, 128)       \n",
    "\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.logits  = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self,audio_input):\n",
    "        #Audio Branch \n",
    "        audio_db = self.to_db(audio_input) #[FIX! think need to upgrade torch]\n",
    "        audio_norm = self.a_norming(audio_db) \n",
    "        \n",
    "        x_audio = self.conv1(audio_norm)\n",
    "        x_audio = self.conv2(x_audio)\n",
    "        x_audio = self.conv3(x_audio)\n",
    "        x_audio = self.conv4(x_audio)\n",
    "\n",
    "        x_audio = x_audio.view(x_audio.size(0), -1)\n",
    "        x_audio = F.relu(self.a_fc1(x_audio))\n",
    "        x_audio = F.relu(self.a_fc2(x_audio))\n",
    "        x_audio = F.relu(self.a_fc3(x_audio))\n",
    "        \n",
    "        #Merged Branch\n",
    "        x_audio = self.drop(x_audio)\n",
    "        logits = self.logits(x_audio)\n",
    "        output = torch.sigmoid(logits)\n",
    "        return output, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T12:59:16.019598Z",
     "start_time": "2021-10-29T12:59:16.015794Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# get VAD\n",
    "def get_VAD(device):\n",
    "    # Define loss and optimizer\n",
    "    vad_model = VAD()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(vad_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    vad_model.to(device)\n",
    "    return vad_model, optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:26:21.673845Z",
     "start_time": "2021-10-29T13:26:21.648026Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_vad(vad_model, train_loader, optimizer, criterion):\n",
    "    for epoch in range(NUM_EPOCHS):  # loop over the dataset multiple times\n",
    "        vad_model.train()\n",
    "        epoch_loss = 0.0\n",
    "        correct = 0\n",
    "        # iterate the training set\n",
    "        with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "            for data in tepoch:\n",
    "                #tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "\n",
    "                # I split each input into 3 second segments (those together will make a batch)\n",
    "                mel_in = data[0].to(device)\n",
    "                labels = torch.squeeze(data[1]).to(device)\n",
    "\n",
    "                # Choosing 3 seconds partitioning -> 92 frames\n",
    "                half_window = int(FRAMES_3SEC/2)\n",
    "                padded_mel = torch.zeros(1,1,128,mel_in.shape[3] + FRAMES_3SEC) #Padding input with 3 seconds of silence\n",
    "                padded_mel[:,:,:,half_window:mel_in.shape[3]+half_window] = mel_in\n",
    "\n",
    "                #for batch in np.arange(0,num_batches):\n",
    "                partitioned_mels_3secs = torch.zeros(mel_in.shape[3],1,128,FRAMES_3SEC)\n",
    "                label_centerframe = torch.zeros(mel_in.shape[3], 1)\n",
    "\n",
    "                # Process all the frames (which starts from half_window in the padded mel, and lasts for all frames)\n",
    "                for idx, central_frame in enumerate(np.arange(half_window,mel_in.shape[3]+half_window-1,1)):\n",
    "                    partitioned_mels_3secs[idx,:,:,:] = padded_mel[:,:,:,central_frame-half_window:central_frame+half_window]\n",
    "                    label_centerframe[idx] = labels[idx] # I should just use labels, now they are identical [obsolete]\n",
    "                    \n",
    "                partitioned_mels_3secs = partitioned_mels_3secs.to(device)\n",
    "                label_centerframe = label_centerframe.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs,logits = vad_model(partitioned_mels_3secs) # (here each \"batch\" is a partitioned frame)\n",
    "                loss = criterion(logits, label_centerframe)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                rounded_output = torch.round(outputs.data)\n",
    "                sample_accuracy  = (rounded_output == label_centerframe).sum().item() / label_centerframe.shape[0]\n",
    "\n",
    "                # compute epoch loss\n",
    "                epoch_loss += loss.item()\n",
    "                tepoch.set_postfix(loss=loss.item(), sample_accuracy=sample_accuracy)\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation scripts [Not used eventually]\n",
    "def evaluate_model(test_pred_prob, test_pred, test_classes):\n",
    "    # Accuracy\n",
    "    accuracy = 100 * accuracy_score(test_classes, test_pred)\n",
    "    print(\"Exact match accuracy is: \" + str(accuracy) + \"%\")\n",
    "    # Area Under the Receiver Operating Characteristic Curve (ROC AUC)\n",
    "    auc_roc = roc_auc_score(test_classes, test_pred_prob)\n",
    "    print(\"Macro Area Under the Curve (AUC) is: \" + str(auc_roc))\n",
    "    return accuracy, auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of the model\n",
    "def test_VAD(vad_model, test_loader, results_path):\n",
    "    # Initialize lists where we save all results and GT\n",
    "    all_groundtruth = []\n",
    "    all_predictions = []\n",
    "    all_predictions_probs = []\n",
    "    \n",
    "    vad_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, data in enumerate(test_loader):\n",
    "            if(step%10 == 0):\n",
    "                print(\"Sample number: \" + str(step) + \" out of: \" + str(len(test_loader)))\n",
    "            mel_in = data[0].to(device)\n",
    "            labels = torch.squeeze(data[1]).to(device)\n",
    "            \n",
    "            # Choosing 3 seconds partitioning -> 92 frames\n",
    "            half_window = int(FRAMES_3SEC/2)\n",
    "            padded_mel = torch.zeros(1,1,128,mel_in.shape[3] + FRAMES_3SEC) #Padding input to have 3 seconds of silence\n",
    "            padded_mel[:,:,:,half_window:mel_in.shape[3]+half_window] = mel_in\n",
    "\n",
    "            #for batch in np.arange(0,num_batches):\n",
    "            partitioned_mels_3secs = torch.zeros(mel_in.shape[3],1,128,FRAMES_3SEC)\n",
    "            label_centerframe = torch.zeros(mel_in.shape[3], 1)\n",
    "\n",
    "            # Process all the frames (which starts from half_window in the padded mel, and lasts for all frames)\n",
    "            for idx, central_frame in enumerate(np.arange(half_window,mel_in.shape[3]+half_window-1,1)):\n",
    "                partitioned_mels_3secs[idx,:,:,:] = padded_mel[:,:,:,central_frame-half_window:central_frame+half_window]\n",
    "                label_centerframe[idx] = labels[idx] # I should just use labels, now they are identical\n",
    "\n",
    "            partitioned_mels_3secs = partitioned_mels_3secs.to(device)\n",
    "            label_centerframe = label_centerframe.to(device)\n",
    "            \n",
    "            outputs, logits = vad_model(partitioned_mels_3secs)\n",
    "            \n",
    "            rounded_output = torch.round(outputs.data)\n",
    "            \n",
    "            all_groundtruth.append(label_centerframe.cpu())\n",
    "            all_predictions.append(rounded_output.cpu())\n",
    "            all_predictions_probs.append(outputs.cpu())\n",
    "\n",
    "    #accuracy_out, auc_roc = evaluate_model(all_predictions_probs,all_predictions, all_groundtruth)\n",
    "    #results = create_analysis_report(test_pred_prob, test_labels, labels_list)\n",
    "    \n",
    "    #np.save(results_path + \"VAD_test_gt.npy\", test_labels)\n",
    "    #np.save(results_path + \"VAD_pred_prob.npy\", test_pred_prob)\n",
    "    #results.to_csv(results_path + \"VAD_report.csv\")\n",
    "    return all_groundtruth, all_predictions, all_predictions_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dataset pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:26:24.300056Z",
     "start_time": "2021-10-29T13:26:24.275133Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining dataset pipeline \n",
    "class VAD_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_directory,  device = 'cpu'):\n",
    "        filenames = os.listdir(data_directory)\n",
    "        self.df = pd.DataFrame(filenames)\n",
    "        self.data_directory = data_directory\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_id = self.df.loc[index].values[0]\n",
    "        data = np.load(self.data_directory + str(file_id))\n",
    "        spectrogram = torch.from_numpy(data['mel'])\n",
    "        label = torch.from_numpy(data['labels']) \n",
    "        if(spectrogram.dim() == 2):\n",
    "            spectrogram = torch.unsqueeze(spectrogram,0)\n",
    "        return spectrogram , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:26:24.852781Z",
     "start_time": "2021-10-29T13:26:24.844875Z"
    }
   },
   "outputs": [],
   "source": [
    "# initiating dataloader \n",
    "def initialize_dataloaders(trainDataDir, testDataDir):        \n",
    "    train_instance = VAD_Dataset(trainDataDir)\n",
    "    test_instance = VAD_Dataset(testDataDir)\n",
    "    \n",
    "    # I am setting the batch size to 1, because I will be batching each input file \n",
    "    # by partitioning around moving central frame\n",
    "    train_loader = torch.utils.data.DataLoader(train_instance,batch_size=1,shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_instance,batch_size=1,shuffle=False)\n",
    "    \n",
    "    #validation_instance = VAD_Dataset(\"MAKE_VALIDATION\")\n",
    "    #valid_loader = torch.utils.data.DataLoader(validation_instance,batch_size=1,shuffle=True)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:20:50.072757Z",
     "start_time": "2021-10-29T13:20:50.065634Z"
    }
   },
   "source": [
    "## Train on original recording without spatial processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:19:19.559965Z",
     "start_time": "2021-10-29T13:19:19.556572Z"
    }
   },
   "outputs": [],
   "source": [
    "trainDataDir = \"/srv/workspace/research/mounted/vad_train_set/original_mels_labels/\"\n",
    "testDataDir = \"/srv/workspace/research/mounted/vad_test_set/original_mels_labels/\" \n",
    "results_path = \"/srv/workspace/research/mounted/results/\"\n",
    "model_save_path = \"/srv/workspace/research/mounted/saved_models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:19:19.559965Z",
     "start_time": "2021-10-29T13:19:19.556572Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [03:38<00:00,  4.31batch/s, loss=0.059, sample_accuracy=0.983] \n",
      "100%|██████████| 957/957 [03:39<00:00,  4.41batch/s, loss=0.0276, sample_accuracy=0.993]\n",
      "100%|██████████| 957/957 [03:38<00:00,  4.30batch/s, loss=0.0469, sample_accuracy=0.987]\n",
      "100%|██████████| 957/957 [03:39<00:00,  4.29batch/s, loss=0.0452, sample_accuracy=0.984]\n",
      "100%|██████████| 957/957 [03:39<00:00,  4.78batch/s, loss=0.0425, sample_accuracy=0.986]\n",
      "100%|██████████| 957/957 [03:39<00:00,  4.21batch/s, loss=0.0339, sample_accuracy=0.989]\n",
      "100%|██████████| 957/957 [03:38<00:00,  4.83batch/s, loss=0.0155, sample_accuracy=0.996]\n",
      "100%|██████████| 957/957 [03:38<00:00,  4.09batch/s, loss=0.0465, sample_accuracy=0.983]\n",
      "100%|██████████| 957/957 [03:38<00:00,  4.59batch/s, loss=0.0351, sample_accuracy=0.99]  \n",
      "100%|██████████| 957/957 [03:38<00:00,  4.22batch/s, loss=0.0783, sample_accuracy=0.975] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "#BATCH_SIZE = 32 # (Replaced batches with partitioned frames)\n",
    "FRAMES_3SEC = 92\n",
    "# Early stop parameters (not applied yet)\n",
    "#min_val_loss = 10**5 #just initialize with random big number \n",
    "#epochs_no_improve = 5\n",
    "#n_epochs_stop = 10\n",
    "\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))\n",
    "\n",
    "# Load datasets\n",
    "train_loader, test_loader = initialize_dataloaders(trainDataDir, testDataDir)\n",
    "\n",
    "# Get model and train\n",
    "vad_model, optimizer, criterion = get_VAD(device)\n",
    "train_vad(vad_model, train_loader, optimizer, criterion)\n",
    "\n",
    "model_name = model_save_path + \"noSpatialProcessing\"\n",
    "torch.save(vad_model.state_dict(),model_name)\n",
    "torch.cuda.empty_cache()\n",
    "print(\"================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:19:26.142393Z",
     "start_time": "2021-10-29T13:19:26.134534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n"
     ]
    }
   ],
   "source": [
    "# Run model on the testset\n",
    "all_groundtruth, all_predictions, all_predictions_probs = test_VAD(vad_model, test_loader, results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:19:33.904531Z",
     "start_time": "2021-10-29T13:19:33.900850Z"
    }
   },
   "outputs": [],
   "source": [
    "# Propoerly format output for evaluation\n",
    "flat_gt = np.asarray([item.numpy()[0] for sublist in all_groundtruth for item in sublist])\n",
    "flat_predictions_probs = np.asarray([item.numpy()[0] for sublist in all_predictions_probs for item in sublist])\n",
    "flat_predictions = np.asarray([item.numpy()[0] for sublist in all_predictions for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:10:19.987925Z",
     "start_time": "2021-10-29T13:10:19.972831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 92.64%\n",
      "AUC = 0.985\n",
      "SHR =  0.904\n",
      "NHR =  0.966\n",
      "Precision = 0.979\n",
      "Recall (same as SHR) =  0.904\n",
      "F1-score = 0.940\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "accuracy  = (flat_predictions == flat_gt).sum() / len(flat_gt)\n",
    "print (\"Accuracy = %0.2f%%\" % (accuracy*100))\n",
    "\n",
    "auc_roc = roc_auc_score(flat_gt, flat_predictions_probs)\n",
    "print (\"AUC = %0.3f\" % auc_roc)\n",
    "\n",
    "true_positives_ratio_perclass = sum((flat_predictions == flat_gt) * (flat_gt == 1)) / sum(flat_gt)\n",
    "print (\"SHR =  %0.3f\" % true_positives_ratio_perclass)\n",
    "\n",
    "true_negative_ratio_perclass = sum((flat_predictions == flat_gt) * (flat_gt == 0)) / (len(flat_gt) - sum(flat_gt))\n",
    "print (\"NHR =  %0.3f\" % true_negative_ratio_perclass)\n",
    "\n",
    "precision = precision_score(flat_gt, flat_predictions)\n",
    "print (\"Precision = %0.3f\" % precision)\n",
    "\n",
    "recall = recall_score(flat_gt, flat_predictions)\n",
    "print (\"Recall (same as SHR) =  %0.3f\" % recall)\n",
    "\n",
    "f1 = f1_score(flat_gt, flat_predictions)\n",
    "print (\"F1-score = %0.3f\" % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:13:33.287595Z",
     "start_time": "2021-10-29T13:13:33.284182Z"
    }
   },
   "source": [
    "## Apply model on all possible spatial modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delay-and-sum based models (In this notebook I didn't do both together because the data wasn't ready yet)\n",
    "spatial_modules = [\"das\", \"das_spectral\", \"das_wiener\", \"das_spectral_filtered\", \"das_wiener_filtered\"]\n",
    "#                  ,\"mvdr\", \"mvdr_spectral\", \"mvdr_wiener\", \"mvdr_spectral_filtered\", \"mvdr_wiener_filtered\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:2\n",
      "================================================================\n",
      "Running experiment: das\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [03:41<00:00,  4.56batch/s, loss=0.0632, sample_accuracy=0.978]\n",
      "100%|██████████| 957/957 [03:45<00:00,  4.11batch/s, loss=0.0656, sample_accuracy=0.977]\n",
      "100%|██████████| 957/957 [03:43<00:00,  3.74batch/s, loss=0.0684, sample_accuracy=0.971]\n",
      "100%|██████████| 957/957 [03:45<00:00,  4.07batch/s, loss=0.064, sample_accuracy=0.979] \n",
      "100%|██████████| 957/957 [03:45<00:00,  3.97batch/s, loss=0.0449, sample_accuracy=0.983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n",
      "Accuracy = 94.72%\n",
      "AUC = 0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHR (Recall) =  0.936\n",
      "NHR =  0.966\n",
      "Precision = 0.980\n",
      "F1-score = 0.958\n",
      "================================================================\n",
      "\n",
      "\n",
      "================================================================\n",
      "Running experiment: das_spectral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [03:43<00:00,  4.11batch/s, loss=0.0641, sample_accuracy=0.978]\n",
      "100%|██████████| 957/957 [03:44<00:00,  3.97batch/s, loss=0.067, sample_accuracy=0.983] \n",
      "100%|██████████| 957/957 [03:45<00:00,  3.68batch/s, loss=0.0676, sample_accuracy=0.978]\n",
      "100%|██████████| 957/957 [03:45<00:00,  5.43batch/s, loss=0.0256, sample_accuracy=0.988] \n",
      "100%|██████████| 957/957 [03:45<00:00,  3.86batch/s, loss=0.0868, sample_accuracy=0.974] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n",
      "Accuracy = 96.41%\n",
      "AUC = 0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHR (Recall) =  0.976\n",
      "NHR =  0.943\n",
      "Precision = 0.968\n",
      "F1-score = 0.972\n",
      "================================================================\n",
      "\n",
      "\n",
      "================================================================\n",
      "Running experiment: das_wiener\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [03:44<00:00,  3.89batch/s, loss=0.0938, sample_accuracy=0.972]\n",
      "100%|██████████| 957/957 [03:45<00:00,  5.09batch/s, loss=0.0309, sample_accuracy=0.99] \n",
      "100%|██████████| 957/957 [03:43<00:00,  6.02batch/s, loss=0.0839, sample_accuracy=0.964]\n",
      "100%|██████████| 957/957 [03:43<00:00,  4.48batch/s, loss=0.0847, sample_accuracy=0.965]\n",
      "100%|██████████| 957/957 [03:44<00:00,  3.94batch/s, loss=0.0753, sample_accuracy=0.966]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n",
      "Accuracy = 94.13%\n",
      "AUC = 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHR (Recall) =  0.958\n",
      "NHR =  0.912\n",
      "Precision = 0.951\n",
      "F1-score = 0.954\n",
      "================================================================\n",
      "\n",
      "\n",
      "================================================================\n",
      "Running experiment: das_spectral_filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [03:45<00:00,  4.05batch/s, loss=0.256, sample_accuracy=0.955] \n",
      "100%|██████████| 957/957 [03:44<00:00,  4.42batch/s, loss=0.0481, sample_accuracy=0.983]\n",
      "100%|██████████| 957/957 [03:44<00:00,  4.78batch/s, loss=0.0433, sample_accuracy=0.98] \n",
      "100%|██████████| 957/957 [03:43<00:00,  4.20batch/s, loss=0.0406, sample_accuracy=0.984]\n",
      "100%|██████████| 957/957 [03:44<00:00,  4.06batch/s, loss=0.0664, sample_accuracy=0.979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n",
      "Accuracy = 93.89%\n",
      "AUC = 0.991\n",
      "SHR (Recall) =  0.916\n",
      "NHR =  0.980\n",
      "Precision = 0.988\n",
      "F1-score = 0.950\n",
      "================================================================\n",
      "\n",
      "\n",
      "================================================================\n",
      "Running experiment: das_wiener_filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [03:43<00:00,  4.16batch/s, loss=0.0631, sample_accuracy=0.975]\n",
      "100%|██████████| 957/957 [03:45<00:00,  4.27batch/s, loss=0.0363, sample_accuracy=0.991]\n",
      "100%|██████████| 957/957 [03:44<00:00,  4.80batch/s, loss=0.0352, sample_accuracy=0.99] \n",
      "100%|██████████| 957/957 [03:44<00:00,  4.14batch/s, loss=0.0888, sample_accuracy=0.969]\n",
      "100%|██████████| 957/957 [03:44<00:00,  4.42batch/s, loss=0.114, sample_accuracy=0.975] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n",
      "Accuracy = 94.44%\n",
      "AUC = 0.987\n",
      "SHR (Recall) =  0.958\n",
      "NHR =  0.920\n",
      "Precision = 0.955\n",
      "F1-score = 0.956\n",
      "================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The main training and testing loop\n",
    "NUM_EPOCHS = 5\n",
    "FRAMES_3SEC = 92\n",
    "results_path = \"/srv/workspace/research/mounted/results/\"\n",
    "model_save_path = \"/srv/workspace/research/mounted/saved_models/\"\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))\n",
    "\n",
    "# Iterate through all the spatial modules\n",
    "for spatial_module in spatial_modules:\n",
    "    print(\"================================================================\")\n",
    "    print(\"Running experiment: \" + spatial_module)\n",
    "    # Load the preprocessed datasets based on the module\n",
    "    trainDataDir = \"/srv/workspace/research/mounted/vad_train_set/\" + spatial_module + \"_mels_labels/\"\n",
    "    testDataDir = \"/srv/workspace/research/mounted/vad_test_set/\" + spatial_module + \"_mels_labels/\"\n",
    "    train_loader, test_loader = initialize_dataloaders(trainDataDir, testDataDir)\n",
    "\n",
    "    # Training the model\n",
    "    vad_model, optimizer, criterion = get_VAD(device)\n",
    "    train_vad(vad_model, train_loader, optimizer, criterion)\n",
    "    model_name = model_save_path + spatial_module\n",
    "    torch.save(vad_model.state_dict(),model_name)\n",
    "    \n",
    "    # Testing the model \n",
    "    all_groundtruth, all_predictions, all_predictions_probs = test_VAD(vad_model, test_loader, results_path)\n",
    "    flat_gt = np.asarray([item.numpy()[0] for sublist in all_groundtruth for item in sublist])\n",
    "    flat_predictions_probs = np.asarray([item.numpy()[0] for sublist in all_predictions_probs for item in sublist])\n",
    "    flat_predictions = np.asarray([item.numpy()[0] for sublist in all_predictions for item in sublist])\n",
    "    \n",
    "    accuracy  = (flat_predictions == flat_gt).sum() / len(flat_gt)\n",
    "    print (\"Accuracy = %0.2f%%\" % (accuracy*100))\n",
    "    auc_roc = roc_auc_score(flat_gt, flat_predictions_probs)\n",
    "    print (\"AUC = %0.3f\" % auc_roc)\n",
    "    true_positives_ratio_perclass = sum((flat_predictions == flat_gt) * (flat_gt == 1)) / sum(flat_gt)\n",
    "    print (\"SHR (Recall) =  %0.3f\" % true_positives_ratio_perclass)\n",
    "    true_negative_ratio_perclass = sum((flat_predictions == flat_gt) * (flat_gt == 0)) / (len(flat_gt) - sum(flat_gt))\n",
    "    print (\"NHR =  %0.3f\" % true_negative_ratio_perclass)\n",
    "    precision = precision_score(flat_gt, flat_predictions)\n",
    "    print (\"Precision = %0.3f\" % precision)\n",
    "    f1 = f1_score(flat_gt, flat_predictions)\n",
    "    print (\"F1-score = %0.3f\" % f1)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"================================================================\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mvdr based models (I reran the experiments once the data was ready)\n",
    "spatial_modules = [\"mvdr\", \"mvdr_spectral\", \"mvdr_wiener\", \"mvdr_spectral_filtered\", \"mvdr_wiener_filtered\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:2\n",
      "================================================================\n",
      "Running experiment: mvdr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [03:40<00:00,  4.05batch/s, loss=0.0575, sample_accuracy=0.98] \n",
      "100%|██████████| 957/957 [03:40<00:00,  4.07batch/s, loss=0.0813, sample_accuracy=0.97] \n",
      "100%|██████████| 957/957 [03:40<00:00,  3.93batch/s, loss=0.0443, sample_accuracy=0.981] \n",
      "100%|██████████| 957/957 [03:40<00:00,  4.12batch/s, loss=0.0687, sample_accuracy=0.972]\n",
      "100%|██████████| 957/957 [03:40<00:00,  3.72batch/s, loss=0.056, sample_accuracy=0.98]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n",
      "Accuracy = 94.75%\n",
      "AUC = 0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHR (Recall) =  0.935\n",
      "NHR =  0.969\n",
      "Precision = 0.982\n",
      "F1-score = 0.958\n",
      "================================================================\n",
      "\n",
      "\n",
      "================================================================\n",
      "Running experiment: mvdr_spectral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [03:41<00:00,  4.09batch/s, loss=0.236, sample_accuracy=0.905] \n",
      "100%|██████████| 957/957 [03:41<00:00,  4.60batch/s, loss=0.0535, sample_accuracy=0.979]\n",
      "100%|██████████| 957/957 [03:40<00:00,  5.27batch/s, loss=0.0329, sample_accuracy=0.978] \n",
      "100%|██████████| 957/957 [03:41<00:00,  4.26batch/s, loss=0.165, sample_accuracy=0.939] \n",
      "100%|██████████| 957/957 [03:40<00:00,  3.93batch/s, loss=0.0752, sample_accuracy=0.979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n",
      "Accuracy = 94.67%\n",
      "AUC = 0.990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHR (Recall) =  0.985\n",
      "NHR =  0.880\n",
      "Precision = 0.935\n",
      "F1-score = 0.959\n",
      "================================================================\n",
      "\n",
      "\n",
      "================================================================\n",
      "Running experiment: mvdr_wiener\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [03:40<00:00,  4.88batch/s, loss=0.297, sample_accuracy=0.846] \n",
      "100%|██████████| 957/957 [03:40<00:00,  4.66batch/s, loss=0.0517, sample_accuracy=0.979]\n",
      "100%|██████████| 957/957 [03:40<00:00,  4.13batch/s, loss=0.0805, sample_accuracy=0.975]\n",
      "100%|██████████| 957/957 [03:40<00:00,  4.22batch/s, loss=0.104, sample_accuracy=0.937] \n",
      "100%|██████████| 957/957 [03:40<00:00,  4.20batch/s, loss=0.0721, sample_accuracy=0.973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n",
      "Accuracy = 92.65%\n",
      "AUC = 0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHR (Recall) =  0.936\n",
      "NHR =  0.911\n",
      "Precision = 0.948\n",
      "F1-score = 0.942\n",
      "================================================================\n",
      "\n",
      "\n",
      "================================================================\n",
      "Running experiment: mvdr_spectral_filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [03:40<00:00,  4.52batch/s, loss=0.0394, sample_accuracy=0.979]\n",
      "100%|██████████| 957/957 [03:40<00:00,  4.87batch/s, loss=0.0593, sample_accuracy=0.978]\n",
      "100%|██████████| 957/957 [03:41<00:00,  4.46batch/s, loss=0.053, sample_accuracy=0.974] \n",
      "100%|██████████| 957/957 [03:40<00:00,  5.05batch/s, loss=0.0701, sample_accuracy=0.98] \n",
      "100%|██████████| 957/957 [03:40<00:00,  4.45batch/s, loss=0.12, sample_accuracy=0.945]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n",
      "Accuracy = 93.84%\n",
      "AUC = 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHR (Recall) =  0.957\n",
      "NHR =  0.907\n",
      "Precision = 0.947\n",
      "F1-score = 0.952\n",
      "================================================================\n",
      "\n",
      "\n",
      "================================================================\n",
      "Running experiment: mvdr_wiener_filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [03:41<00:00,  4.00batch/s, loss=0.362, sample_accuracy=0.861] \n",
      "100%|██████████| 957/957 [03:40<00:00,  4.04batch/s, loss=0.0654, sample_accuracy=0.979]\n",
      "100%|██████████| 957/957 [03:40<00:00,  4.85batch/s, loss=0.13, sample_accuracy=0.961]  \n",
      "100%|██████████| 957/957 [03:40<00:00,  3.89batch/s, loss=0.196, sample_accuracy=0.903] \n",
      "100%|██████████| 957/957 [03:40<00:00,  4.03batch/s, loss=0.0757, sample_accuracy=0.97] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n",
      "Accuracy = 93.33%\n",
      "AUC = 0.982\n",
      "SHR (Recall) =  0.963\n",
      "NHR =  0.881\n",
      "Precision = 0.934\n",
      "F1-score = 0.948\n",
      "================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "FRAMES_3SEC = 92\n",
    "results_path = \"/srv/workspace/research/mounted/results/\"\n",
    "model_save_path = \"/srv/workspace/research/mounted/saved_models/\"\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))\n",
    "\n",
    "for spatial_module in spatial_modules:\n",
    "    print(\"================================================================\")\n",
    "    print(\"Running experiment: \" + spatial_module)\n",
    "    trainDataDir = \"/srv/workspace/research/mounted/vad_train_set/\" + spatial_module + \"_mels_labels/\"\n",
    "    testDataDir = \"/srv/workspace/research/mounted/vad_test_set/\" + spatial_module + \"_mels_labels/\"\n",
    "\n",
    "    train_loader, test_loader = initialize_dataloaders(trainDataDir, testDataDir)\n",
    "\n",
    "    # Training the model\n",
    "    vad_model, optimizer, criterion = get_VAD(device)\n",
    "    train_vad(vad_model, train_loader, optimizer, criterion)\n",
    "    model_name = model_save_path + spatial_module\n",
    "    torch.save(vad_model.state_dict(),model_name)\n",
    "    \n",
    "    # Testing the model \n",
    "    all_groundtruth, all_predictions, all_predictions_probs = test_VAD(vad_model, test_loader, results_path)\n",
    "    flat_gt = np.asarray([item.numpy()[0] for sublist in all_groundtruth for item in sublist])\n",
    "    flat_predictions_probs = np.asarray([item.numpy()[0] for sublist in all_predictions_probs for item in sublist])\n",
    "    flat_predictions = np.asarray([item.numpy()[0] for sublist in all_predictions for item in sublist])\n",
    "    \n",
    "    accuracy  = (flat_predictions == flat_gt).sum() / len(flat_gt)\n",
    "    print (\"Accuracy = %0.2f%%\" % (accuracy*100))\n",
    "    auc_roc = roc_auc_score(flat_gt, flat_predictions_probs)\n",
    "    print (\"AUC = %0.3f\" % auc_roc)\n",
    "    true_positives_ratio_perclass = sum((flat_predictions == flat_gt) * (flat_gt == 1)) / sum(flat_gt)\n",
    "    print (\"SHR (Recall) =  %0.3f\" % true_positives_ratio_perclass)\n",
    "    true_negative_ratio_perclass = sum((flat_predictions == flat_gt) * (flat_gt == 0)) / (len(flat_gt) - sum(flat_gt))\n",
    "    print (\"NHR =  %0.3f\" % true_negative_ratio_perclass)\n",
    "    precision = precision_score(flat_gt, flat_predictions)\n",
    "    print (\"Precision = %0.3f\" % precision)\n",
    "    f1 = f1_score(flat_gt, flat_predictions)\n",
    "    print (\"F1-score = %0.3f\" % f1)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"================================================================\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:19:56.385408Z",
     "start_time": "2021-10-29T13:19:56.357330Z"
    }
   },
   "source": [
    "## Apply post-processing\n",
    "Planned but not achieved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
