{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:27:17.205585Z",
     "start_time": "2021-10-29T13:27:17.189508Z"
    }
   },
   "outputs": [],
   "source": [
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import f1_score,accuracy_score, precision_score, recall_score, classification_report, roc_auc_score\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "    This model is identical to the CNN model, except for adding an LSTM layer instead of the dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:27:37.801715Z",
     "start_time": "2021-10-29T13:27:37.780765Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# VAD model\n",
    "class Conv_2d(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, shape=3, stride=1, pooling=2):\n",
    "        super(Conv_2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(input_channels, output_channels, shape, stride=stride, padding=shape//2)\n",
    "        self.bn = nn.BatchNorm2d(output_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.mp = nn.MaxPool2d(pooling)\n",
    "    def forward(self, x):\n",
    "        out = self.mp(self.relu(self.bn(self.conv(x))))\n",
    "        #out = self.mp(self.relu(self.conv(x)))\n",
    "        return out\n",
    "\n",
    "class VAD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAD, self).__init__()\n",
    "        self.a_norming = nn.BatchNorm2d(1) \n",
    "        self.to_db = torchaudio.transforms.AmplitudeToDB() \n",
    "\n",
    "        self.conv1 = Conv_2d(1,32)\n",
    "        self.conv2 = Conv_2d(32,64)\n",
    "        self.conv3 = Conv_2d(64,128)\n",
    "        self.conv4 = Conv_2d(128,256)\n",
    "        \n",
    "        self.a_fc1 =  nn.Linear(10240, 512)\n",
    "        \n",
    "        self.lstm = nn.LSTM(512, 128, 2, batch_first = True)\n",
    "        \n",
    "        #self.a_fc2 = nn.Linear(512, 256)\n",
    "        #self.a_fc3 = nn.Linear(256, 128)       \n",
    "\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.logits  = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self,audio_input):\n",
    "        #Audio Branch \n",
    "        audio_db = self.to_db(audio_input)\n",
    "        audio_norm = self.a_norming(audio_db) \n",
    "        \n",
    "        x_audio = self.conv1(audio_norm)\n",
    "        x_audio = self.conv2(x_audio)\n",
    "        x_audio = self.conv3(x_audio)\n",
    "        x_audio = self.conv4(x_audio)\n",
    "\n",
    "        x_audio = x_audio.view(x_audio.size(0), -1)\n",
    "        x_audio = F.relu(self.a_fc1(x_audio))\n",
    "        x_audio = torch.unsqueeze(x_audio, 0) # So what I do here is to swap the batch_dim with the seq_dim\n",
    "        x_audio,_ = self.lstm(x_audio)\n",
    "        #x_audio = F.relu(self.a_fc1(x_audio))\n",
    "        #x_audio = F.relu(self.a_fc2(x_audio))\n",
    "        #x_audio = F.relu(self.a_fc3(x_audio))\n",
    "        \n",
    "        x_audio = self.drop(x_audio)\n",
    "        logits = self.logits(x_audio)\n",
    "        output = torch.sigmoid(logits)\n",
    "        output = torch.squeeze(output, 0)\n",
    "        logits = torch.squeeze(logits, 0)\n",
    "        return output, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T12:59:16.019598Z",
     "start_time": "2021-10-29T12:59:16.015794Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# get VAD\n",
    "def get_VAD(device):\n",
    "    # Define loss and optimizer\n",
    "    vad_model = VAD()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(vad_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    vad_model.to(device)\n",
    "    return vad_model, optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:26:21.673845Z",
     "start_time": "2021-10-29T13:26:21.648026Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_vad(vad_model, train_loader, optimizer, criterion):\n",
    "    for epoch in range(NUM_EPOCHS):  # loop over the dataset multiple times\n",
    "        vad_model.train()\n",
    "        epoch_loss = 0.0\n",
    "        correct = 0\n",
    "        # iterate the training set\n",
    "        with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "            for data in tepoch:\n",
    "                #tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "\n",
    "                # I split each input into 3 second segments (those together will make a batch)\n",
    "                mel_in = data[0].to(device)\n",
    "                labels = torch.squeeze(data[1]).to(device)\n",
    "\n",
    "                # Choosing 3 seconds partitioning -> 92 frames\n",
    "                half_window = int(FRAMES_3SEC/2)\n",
    "                padded_mel = torch.zeros(1,1,128,mel_in.shape[3] + FRAMES_3SEC) #Padding input to have 3 seconds of silence\n",
    "                padded_mel[:,:,:,half_window:mel_in.shape[3]+half_window] = mel_in\n",
    "                #num_batches = (padded_mel.shape[3] - FRAMES_3SEC) / BATCH_SIZE # Because we will ignore the first 92 frames\n",
    "\n",
    "                #for batch in np.arange(0,num_batches):\n",
    "                partitioned_mels_3secs = torch.zeros(mel_in.shape[3],1,128,FRAMES_3SEC)\n",
    "                label_centerframe = torch.zeros(mel_in.shape[3], 1)\n",
    "\n",
    "                # Process all the frames (which starts from half_window in the padded mel, and lasts for all frames)\n",
    "                for idx, central_frame in enumerate(np.arange(half_window,mel_in.shape[3]+half_window-1,1)):\n",
    "                    partitioned_mels_3secs[idx,:,:,:] = padded_mel[:,:,:,central_frame-half_window:central_frame+half_window]\n",
    "                    label_centerframe[idx] = labels[idx] # I should just use labels, now they are identical\n",
    "                    \n",
    "                partitioned_mels_3secs = partitioned_mels_3secs.to(device)\n",
    "                label_centerframe = label_centerframe.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs,logits = vad_model(partitioned_mels_3secs) # (here each \"batch\" is a partitioned frame)\n",
    "                loss = criterion(logits, label_centerframe)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                rounded_output = torch.round(outputs.data)\n",
    "                sample_accuracy  = (rounded_output == label_centerframe).sum().item() / label_centerframe.shape[0]\n",
    "\n",
    "                # compute epoch loss\n",
    "                epoch_loss += loss.item()\n",
    "                tepoch.set_postfix(loss=loss.item(), sample_accuracy=sample_accuracy)\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation scripts\n",
    "def evaluate_model(test_pred_prob, test_pred, test_classes):\n",
    "    # Accuracy\n",
    "    accuracy = 100 * accuracy_score(test_classes, test_pred)\n",
    "    print(\"Exact match accuracy is: \" + str(accuracy) + \"%\")\n",
    "    # Area Under the Receiver Operating Characteristic Curve (ROC AUC)\n",
    "    auc_roc = roc_auc_score(test_classes, test_pred_prob)\n",
    "    print(\"Macro Area Under the Curve (AUC) is: \" + str(auc_roc))\n",
    "    return accuracy, auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of the model\n",
    "def test_VAD(vad_model, test_loader, results_path):\n",
    "    # Initialize lists where we save all results and GT\n",
    "    all_groundtruth = []\n",
    "    all_predictions = []\n",
    "    all_predictions_probs = []\n",
    "    \n",
    "    vad_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, data in enumerate(test_loader):\n",
    "            if(step%10 == 0):\n",
    "                print(\"Sample number: \" + str(step) + \" out of: \" + str(len(test_loader)))\n",
    "            mel_in = data[0].to(device)\n",
    "            labels = torch.squeeze(data[1]).to(device)\n",
    "            \n",
    "            # Choosing 3 seconds partitioning -> 92 frames\n",
    "            half_window = int(FRAMES_3SEC/2)\n",
    "            padded_mel = torch.zeros(1,1,128,mel_in.shape[3] + FRAMES_3SEC) #Padding input to have 3 seconds of silence at the end\n",
    "            padded_mel[:,:,:,half_window:mel_in.shape[3]+half_window] = mel_in\n",
    "            #num_batches = (padded_mel.shape[3] - FRAMES_3SEC) / BATCH_SIZE # Because we will ignore the first 92 frames\n",
    "\n",
    "            #for batch in np.arange(0,num_batches):\n",
    "            partitioned_mels_3secs = torch.zeros(mel_in.shape[3],1,128,FRAMES_3SEC)\n",
    "            label_centerframe = torch.zeros(mel_in.shape[3], 1)\n",
    "\n",
    "            # Process all the frames (which starts from half_window in the padded mel, and lasts for all frames)\n",
    "            for idx, central_frame in enumerate(np.arange(half_window,mel_in.shape[3]+half_window-1,1)):\n",
    "                partitioned_mels_3secs[idx,:,:,:] = padded_mel[:,:,:,central_frame-half_window:central_frame+half_window]\n",
    "                label_centerframe[idx] = labels[idx] # I should just use labels, now they are identical\n",
    "\n",
    "            partitioned_mels_3secs = partitioned_mels_3secs.to(device)\n",
    "            label_centerframe = label_centerframe.to(device)\n",
    "            \n",
    "            outputs, logits = vad_model(partitioned_mels_3secs)\n",
    "            \n",
    "            rounded_output = torch.round(outputs.data)\n",
    "            \n",
    "            all_groundtruth.append(label_centerframe.cpu())\n",
    "            all_predictions.append(rounded_output.cpu())\n",
    "            all_predictions_probs.append(outputs.cpu())\n",
    "\n",
    "    #accuracy_out, auc_roc = evaluate_model(all_predictions_probs,all_predictions, all_groundtruth)\n",
    "    #results = create_analysis_report(test_pred_prob, test_labels, labels_list)\n",
    "    \n",
    "    #np.save(results_path + \"VAD_test_gt.npy\", test_labels)\n",
    "    #np.save(results_path + \"VAD_pred_prob.npy\", test_pred_prob)\n",
    "    #results.to_csv(results_path + \"VAD_report.csv\")\n",
    "    return all_groundtruth, all_predictions, all_predictions_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dataset pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:26:24.300056Z",
     "start_time": "2021-10-29T13:26:24.275133Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining dataset pipeline \n",
    "class VAD_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_directory,  device = 'cpu'):\n",
    "        filenames = os.listdir(data_directory)\n",
    "        self.df = pd.DataFrame(filenames)\n",
    "        self.data_directory = data_directory\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_id = self.df.loc[index].values[0]\n",
    "        data = np.load(self.data_directory + str(file_id))\n",
    "        spectrogram = torch.from_numpy(data['mel'])\n",
    "        label = torch.from_numpy(data['labels'])\n",
    "        \n",
    "        # this is to ensure all mels have same shape (padded if missing)\n",
    "        #mel_spec = torch.zeros(1,128,1292) # SET TO MAX LENGTH\n",
    "        #labels_stretched = torch.zeros(1,1292)\n",
    "        if(spectrogram.dim() == 2):\n",
    "            spectrogram = torch.unsqueeze(spectrogram,0)\n",
    "        #mel_spec[:, :, :spectrogram.shape[2]] = spectrogram\n",
    "        #labels_stretched[:, :label.shape[1]] = label\n",
    "\n",
    "        return spectrogram , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:26:24.852781Z",
     "start_time": "2021-10-29T13:26:24.844875Z"
    }
   },
   "outputs": [],
   "source": [
    "# initiating dataloader \n",
    "def initialize_dataloaders(trainDataDir, testDataDir):        \n",
    "    train_instance = VAD_Dataset(trainDataDir)\n",
    "    test_instance = VAD_Dataset(testDataDir)\n",
    "    \n",
    "    # I am setting the batch size to 1, because I will be batching each input file \n",
    "    # by partitioning around moving central frame\n",
    "    train_loader = torch.utils.data.DataLoader(train_instance,batch_size=1,shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_instance,batch_size=1,shuffle=False)\n",
    "    \n",
    "    #validation_instance = VAD_Dataset(\"MAKE_VALIDATION\")\n",
    "    #valid_loader = torch.utils.data.DataLoader(validation_instance,batch_size=1,shuffle=True)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:20:50.072757Z",
     "start_time": "2021-10-29T13:20:50.065634Z"
    }
   },
   "source": [
    "## Train on original recording without spatial processing \n",
    "(NOTE: I didn't rerun this part for the CRNN, the results presented are from the original CNN model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:19:19.559965Z",
     "start_time": "2021-10-29T13:19:19.556572Z"
    }
   },
   "outputs": [],
   "source": [
    "trainDataDir = \"/srv/workspace/research/mounted/vad_train_set/original_mels_labels/\"\n",
    "testDataDir = \"/srv/workspace/research/mounted/vad_test_set/original_mels_labels/\" \n",
    "results_path = \"/srv/workspace/research/mounted/results/\"\n",
    "model_save_path = \"/srv/workspace/research/mounted/saved_models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:19:19.559965Z",
     "start_time": "2021-10-29T13:19:19.556572Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [03:38<00:00,  4.31batch/s, loss=0.059, sample_accuracy=0.983] \n",
      "100%|██████████| 957/957 [03:39<00:00,  4.41batch/s, loss=0.0276, sample_accuracy=0.993]\n",
      "100%|██████████| 957/957 [03:38<00:00,  4.30batch/s, loss=0.0469, sample_accuracy=0.987]\n",
      "100%|██████████| 957/957 [03:39<00:00,  4.29batch/s, loss=0.0452, sample_accuracy=0.984]\n",
      "100%|██████████| 957/957 [03:39<00:00,  4.78batch/s, loss=0.0425, sample_accuracy=0.986]\n",
      "100%|██████████| 957/957 [03:39<00:00,  4.21batch/s, loss=0.0339, sample_accuracy=0.989]\n",
      "100%|██████████| 957/957 [03:38<00:00,  4.83batch/s, loss=0.0155, sample_accuracy=0.996]\n",
      "100%|██████████| 957/957 [03:38<00:00,  4.09batch/s, loss=0.0465, sample_accuracy=0.983]\n",
      "100%|██████████| 957/957 [03:38<00:00,  4.59batch/s, loss=0.0351, sample_accuracy=0.99]  \n",
      "100%|██████████| 957/957 [03:38<00:00,  4.22batch/s, loss=0.0783, sample_accuracy=0.975] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "#BATCH_SIZE = 32 # (Replaced batches with partitioned frames)\n",
    "FRAMES_3SEC = 92\n",
    "# Early stop parameters (not applied yet)\n",
    "#min_val_loss = 10**5 #just initialize with random big number \n",
    "#epochs_no_improve = 0\n",
    "#n_epochs_stop = 10\n",
    "\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))\n",
    "\n",
    "train_loader, test_loader = initialize_dataloaders(trainDataDir, testDataDir)\n",
    "\n",
    "vad_model, optimizer, criterion = get_VAD(device)\n",
    "train_vad(vad_model, train_loader, optimizer, criterion)\n",
    "\n",
    "model_name = model_save_path + \"noSpatialProcessing\"\n",
    "torch.save(vad_model.state_dict(),model_name)\n",
    "torch.cuda.empty_cache()\n",
    "print(\"================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:19:26.142393Z",
     "start_time": "2021-10-29T13:19:26.134534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "all_groundtruth, all_predictions, all_predictions_probs = test_VAD(vad_model, test_loader, results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:19:33.904531Z",
     "start_time": "2021-10-29T13:19:33.900850Z"
    }
   },
   "outputs": [],
   "source": [
    "# Formatting the output\n",
    "flat_gt = np.asarray([item.numpy()[0] for sublist in all_groundtruth for item in sublist])\n",
    "flat_predictions_probs = np.asarray([item.numpy()[0] for sublist in all_predictions_probs for item in sublist])\n",
    "flat_predictions = np.asarray([item.numpy()[0] for sublist in all_predictions for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:10:19.987925Z",
     "start_time": "2021-10-29T13:10:19.972831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 92.64%\n",
      "AUC = 0.985\n",
      "SHR =  0.904\n",
      "NHR =  0.966\n",
      "Precision = 0.979\n",
      "Recall (same as SHR) =  0.904\n",
      "F1-score = 0.940\n"
     ]
    }
   ],
   "source": [
    "# Evaluation bit\n",
    "accuracy  = (flat_predictions == flat_gt).sum() / len(flat_gt)\n",
    "print (\"Accuracy = %0.2f%%\" % (accuracy*100))\n",
    "\n",
    "auc_roc = roc_auc_score(flat_gt, flat_predictions_probs)\n",
    "print (\"AUC = %0.3f\" % auc_roc)\n",
    "\n",
    "true_positives_ratio_perclass = sum((flat_predictions == flat_gt) * (flat_gt == 1)) / sum(flat_gt)\n",
    "print (\"SHR =  %0.3f\" % true_positives_ratio_perclass)\n",
    "\n",
    "true_negative_ratio_perclass = sum((flat_predictions == flat_gt) * (flat_gt == 0)) / (len(flat_gt) - sum(flat_gt))\n",
    "print (\"NHR =  %0.3f\" % true_negative_ratio_perclass)\n",
    "\n",
    "precision = precision_score(flat_gt, flat_predictions)\n",
    "print (\"Precision = %0.3f\" % precision)\n",
    "\n",
    "recall = recall_score(flat_gt, flat_predictions)\n",
    "print (\"Recall (same as SHR) =  %0.3f\" % recall)\n",
    "\n",
    "f1 = f1_score(flat_gt, flat_predictions)\n",
    "print (\"F1-score = %0.3f\" % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:13:33.287595Z",
     "start_time": "2021-10-29T13:13:33.284182Z"
    }
   },
   "source": [
    "## Apply model on all possible spatial modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delay-and-sum based models\n",
    "spatial_modules = [\"das\", \"das_spectral\", \"das_wiener\", \"das_spectral_filtered\", \"das_wiener_filtered\"\n",
    "                  ,\"mvdr\", \"mvdr_spectral\", \"mvdr_wiener\", \"mvdr_spectral_filtered\", \"mvdr_wiener_filtered\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:2\n",
      "================================================================\n",
      "Running experiment: das\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [04:00<00:00,  4.23batch/s, loss=0.0764, sample_accuracy=0.973]\n",
      "100%|██████████| 957/957 [04:01<00:00,  3.70batch/s, loss=0.109, sample_accuracy=0.956] \n",
      "100%|██████████| 957/957 [04:01<00:00,  5.42batch/s, loss=0.035, sample_accuracy=0.979] \n",
      "100%|██████████| 957/957 [04:01<00:00,  4.03batch/s, loss=0.0294, sample_accuracy=0.991]\n",
      "100%|██████████| 957/957 [04:02<00:00,  3.66batch/s, loss=0.0786, sample_accuracy=0.968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n",
      "Accuracy = 91.51%\n",
      "AUC = 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHR (Recall) =  0.875\n",
      "NHR =  0.985\n",
      "Precision = 0.990\n",
      "F1-score = 0.929\n",
      "================================================================\n",
      "\n",
      "\n",
      "================================================================\n",
      "Running experiment: das_spectral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [04:01<00:00,  3.76batch/s, loss=0.198, sample_accuracy=0.922] \n",
      "100%|██████████| 957/957 [04:01<00:00,  4.51batch/s, loss=0.0911, sample_accuracy=0.967]\n",
      "100%|██████████| 957/957 [04:01<00:00,  4.83batch/s, loss=0.108, sample_accuracy=0.949] \n",
      "100%|██████████| 957/957 [04:01<00:00,  3.94batch/s, loss=0.0497, sample_accuracy=0.982]\n",
      "100%|██████████| 957/957 [04:01<00:00,  3.64batch/s, loss=0.0424, sample_accuracy=0.985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n",
      "Accuracy = 96.40%\n",
      "AUC = 0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHR (Recall) =  0.971\n",
      "NHR =  0.951\n",
      "Precision = 0.972\n",
      "F1-score = 0.972\n",
      "================================================================\n",
      "\n",
      "\n",
      "================================================================\n",
      "Running experiment: das_wiener\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [04:01<00:00,  3.81batch/s, loss=0.0832, sample_accuracy=0.964]\n",
      " 15%|█▌        | 147/957 [00:37<03:09,  4.28batch/s, loss=0.0973, sample_accuracy=0.97] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 957/957 [04:01<00:00,  4.41batch/s, loss=0.486, sample_accuracy=0.86]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n",
      "Accuracy = 62.65%\n",
      "AUC = 0.918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHR (Recall) =  0.416\n",
      "NHR =  0.997\n",
      "Precision = 0.995\n",
      "F1-score = 0.587\n",
      "================================================================\n",
      "\n",
      "\n",
      "================================================================\n",
      "Running experiment: das_spectral_filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [04:01<00:00,  4.21batch/s, loss=0.0954, sample_accuracy=0.967]\n",
      "  2%|▏         | 23/957 [00:05<04:03,  3.83batch/s, loss=0.27, sample_accuracy=0.914]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 957/957 [04:00<00:00,  3.67batch/s, loss=0.0565, sample_accuracy=0.982]\n",
      "100%|██████████| 957/957 [04:00<00:00,  3.89batch/s, loss=0.147, sample_accuracy=0.941] \n",
      "100%|██████████| 957/957 [04:01<00:00,  3.83batch/s, loss=0.0453, sample_accuracy=0.984] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n",
      "Accuracy = 96.21%\n",
      "AUC = 0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHR (Recall) =  0.965\n",
      "NHR =  0.957\n",
      "Precision = 0.975\n",
      "F1-score = 0.970\n",
      "================================================================\n",
      "\n",
      "\n",
      "================================================================\n",
      "Running experiment: das_wiener_filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [04:01<00:00,  3.79batch/s, loss=0.199, sample_accuracy=0.925] \n",
      "100%|██████████| 957/957 [04:01<00:00,  4.18batch/s, loss=0.1, sample_accuracy=0.96]    \n",
      "100%|██████████| 957/957 [04:01<00:00,  3.58batch/s, loss=0.0869, sample_accuracy=0.965]\n",
      "100%|██████████| 957/957 [04:01<00:00,  5.49batch/s, loss=0.151, sample_accuracy=0.938] \n",
      "100%|██████████| 957/957 [04:01<00:00,  3.59batch/s, loss=0.0762, sample_accuracy=0.979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n",
      "Accuracy = 94.21%\n",
      "AUC = 0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHR (Recall) =  0.968\n",
      "NHR =  0.896\n",
      "Precision = 0.943\n",
      "F1-score = 0.955\n",
      "================================================================\n",
      "\n",
      "\n",
      "================================================================\n",
      "Running experiment: mvdr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [04:05<00:00,  3.52batch/s, loss=0.105, sample_accuracy=0.948] \n",
      "100%|██████████| 957/957 [04:02<00:00,  3.69batch/s, loss=0.0516, sample_accuracy=0.986]\n",
      "100%|██████████| 957/957 [04:02<00:00,  4.82batch/s, loss=0.0298, sample_accuracy=0.986]\n",
      "100%|██████████| 957/957 [04:02<00:00,  3.52batch/s, loss=0.217, sample_accuracy=0.931] \n",
      "100%|██████████| 957/957 [04:02<00:00,  3.81batch/s, loss=0.032, sample_accuracy=0.986] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n",
      "Accuracy = 95.87%\n",
      "AUC = 0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHR (Recall) =  0.956\n",
      "NHR =  0.964\n",
      "Precision = 0.979\n",
      "F1-score = 0.967\n",
      "================================================================\n",
      "\n",
      "\n",
      "================================================================\n",
      "Running experiment: mvdr_spectral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [04:04<00:00,  3.61batch/s, loss=0.118, sample_accuracy=0.968] \n",
      "100%|██████████| 957/957 [04:01<00:00,  3.99batch/s, loss=0.206, sample_accuracy=0.906] \n",
      "100%|██████████| 957/957 [04:02<00:00,  3.77batch/s, loss=0.0959, sample_accuracy=0.97] \n",
      "100%|██████████| 957/957 [04:01<00:00,  3.70batch/s, loss=0.174, sample_accuracy=0.924] \n",
      "100%|██████████| 957/957 [04:01<00:00,  3.82batch/s, loss=0.0416, sample_accuracy=0.982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n",
      "Accuracy = 95.01%\n",
      "AUC = 0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHR (Recall) =  0.971\n",
      "NHR =  0.913\n",
      "Precision = 0.952\n",
      "F1-score = 0.961\n",
      "================================================================\n",
      "\n",
      "\n",
      "================================================================\n",
      "Running experiment: mvdr_wiener\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [04:04<00:00,  3.66batch/s, loss=0.0869, sample_accuracy=0.97] \n",
      "100%|██████████| 957/957 [04:01<00:00,  3.78batch/s, loss=0.234, sample_accuracy=0.913] \n",
      "100%|██████████| 957/957 [04:01<00:00,  4.13batch/s, loss=0.0782, sample_accuracy=0.976]\n",
      "100%|██████████| 957/957 [04:01<00:00,  3.63batch/s, loss=0.0957, sample_accuracy=0.967]\n",
      "100%|██████████| 957/957 [04:01<00:00,  3.89batch/s, loss=0.109, sample_accuracy=0.956] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n",
      "Accuracy = 94.12%\n",
      "AUC = 0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHR (Recall) =  0.948\n",
      "NHR =  0.928\n",
      "Precision = 0.959\n",
      "F1-score = 0.954\n",
      "================================================================\n",
      "\n",
      "\n",
      "================================================================\n",
      "Running experiment: mvdr_spectral_filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [04:02<00:00,  4.49batch/s, loss=0.068, sample_accuracy=0.972] \n",
      "100%|██████████| 957/957 [04:01<00:00,  3.83batch/s, loss=0.173, sample_accuracy=0.932] \n",
      "100%|██████████| 957/957 [04:01<00:00,  3.74batch/s, loss=0.0478, sample_accuracy=0.981]\n",
      "100%|██████████| 957/957 [04:01<00:00,  4.02batch/s, loss=0.19, sample_accuracy=0.947]  \n",
      "100%|██████████| 957/957 [04:01<00:00,  4.18batch/s, loss=0.0447, sample_accuracy=0.989]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n",
      "Accuracy = 95.21%\n",
      "AUC = 0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/957 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHR (Recall) =  0.967\n",
      "NHR =  0.927\n",
      "Precision = 0.959\n",
      "F1-score = 0.963\n",
      "================================================================\n",
      "\n",
      "\n",
      "================================================================\n",
      "Running experiment: mvdr_wiener_filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [04:02<00:00,  4.57batch/s, loss=0.109, sample_accuracy=0.96]  \n",
      "100%|██████████| 957/957 [04:01<00:00,  3.65batch/s, loss=0.104, sample_accuracy=0.972] \n",
      "100%|██████████| 957/957 [04:02<00:00,  3.82batch/s, loss=0.128, sample_accuracy=0.961] \n",
      "100%|██████████| 957/957 [04:01<00:00,  4.13batch/s, loss=0.111, sample_accuracy=0.958] \n",
      "100%|██████████| 957/957 [04:01<00:00,  4.05batch/s, loss=0.169, sample_accuracy=0.93]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Sample number: 0 out of: 96\n",
      "Sample number: 10 out of: 96\n",
      "Sample number: 20 out of: 96\n",
      "Sample number: 30 out of: 96\n",
      "Sample number: 40 out of: 96\n",
      "Sample number: 50 out of: 96\n",
      "Sample number: 60 out of: 96\n",
      "Sample number: 70 out of: 96\n",
      "Sample number: 80 out of: 96\n",
      "Sample number: 90 out of: 96\n",
      "Accuracy = 92.70%\n",
      "AUC = 0.977\n",
      "SHR (Recall) =  0.970\n",
      "NHR =  0.851\n",
      "Precision = 0.920\n",
      "F1-score = 0.944\n",
      "================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training and testing the model with each spatial module\n",
    "NUM_EPOCHS = 5\n",
    "FRAMES_3SEC = 92\n",
    "results_path = \"/srv/workspace/research/mounted/results/\"\n",
    "model_save_path = \"/srv/workspace/research/mounted/saved_models/crnn\"\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))\n",
    "\n",
    "for spatial_module in spatial_modules:\n",
    "    print(\"================================================================\")\n",
    "    print(\"Running experiment: \" + spatial_module)\n",
    "    trainDataDir = \"/srv/workspace/research/mounted/vad_train_set/\" + spatial_module + \"_mels_labels/\"\n",
    "    testDataDir = \"/srv/workspace/research/mounted/vad_test_set/\" + spatial_module + \"_mels_labels/\"\n",
    "\n",
    "    train_loader, test_loader = initialize_dataloaders(trainDataDir, testDataDir)\n",
    "\n",
    "    # Training the model\n",
    "    vad_model, optimizer, criterion = get_VAD(device)\n",
    "    train_vad(vad_model, train_loader, optimizer, criterion)\n",
    "    model_name = model_save_path + spatial_module\n",
    "    torch.save(vad_model.state_dict(),model_name)\n",
    "    \n",
    "    # Testing the model \n",
    "    all_groundtruth, all_predictions, all_predictions_probs = test_VAD(vad_model, test_loader, results_path)\n",
    "    flat_gt = np.asarray([item.numpy()[0] for sublist in all_groundtruth for item in sublist])\n",
    "    flat_predictions_probs = np.asarray([item.numpy()[0] for sublist in all_predictions_probs for item in sublist])\n",
    "    flat_predictions = np.asarray([item.numpy()[0] for sublist in all_predictions for item in sublist])\n",
    "    \n",
    "    accuracy  = (flat_predictions == flat_gt).sum() / len(flat_gt)\n",
    "    print (\"Accuracy = %0.2f%%\" % (accuracy*100))\n",
    "    auc_roc = roc_auc_score(flat_gt, flat_predictions_probs)\n",
    "    print (\"AUC = %0.3f\" % auc_roc)\n",
    "    true_positives_ratio_perclass = sum((flat_predictions == flat_gt) * (flat_gt == 1)) / sum(flat_gt)\n",
    "    print (\"SHR (Recall) =  %0.3f\" % true_positives_ratio_perclass)\n",
    "    true_negative_ratio_perclass = sum((flat_predictions == flat_gt) * (flat_gt == 0)) / (len(flat_gt) - sum(flat_gt))\n",
    "    print (\"NHR =  %0.3f\" % true_negative_ratio_perclass)\n",
    "    precision = precision_score(flat_gt, flat_predictions)\n",
    "    print (\"Precision = %0.3f\" % precision)\n",
    "    f1 = f1_score(flat_gt, flat_predictions)\n",
    "    print (\"F1-score = %0.3f\" % f1)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"================================================================\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
