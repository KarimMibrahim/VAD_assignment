{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:04:20.466021Z",
     "start_time": "2021-11-01T19:04:16.841579Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import fftconvolve\n",
    "import IPython\n",
    "import pyroomacoustics as pra\n",
    "from pyroomacoustics.denoise import apply_spectral_sub, apply_iterative_wiener\n",
    "from scipy import signal as sps\n",
    "\n",
    "\n",
    "TRAIN_DIR = \"/home/karim/Desktop/Sonos_Assignment/vad_train_set/\"\n",
    "TEST_DIR = \"/home/karim/Desktop/Sonos_Assignment/vad_test_set/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Spatial Processing\n",
    "In this section, I apply different spatial processing techniques on the input signals. I tested with the following\n",
    "\n",
    "*Beamforming*: 1) delay-and-sum (das) 2) minimum variance distortionless response (mvdr)\n",
    "\n",
    "*Denoising*: 1) spectral subtraction 2) iterative wiener filtering\n",
    "\n",
    "*Bandpass Filtering*: 30Hz-3KHz voice band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T11:32:01.613928Z",
     "start_time": "2021-11-01T11:32:01.597795Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Defining a room through rt60 \n",
    "def get_room(rt60_tgt, fs): \n",
    "    # Setting up room dims\n",
    "    room_dim = [3, 3, 3]  # meters (Assuming a cubic room of 3x3x3 meters - some rt60 were too low for bigger)\n",
    "    room_center = [dim / 2 for dim in room_dim]\n",
    "    # put our michrophone in the center of the room\n",
    "    R = np.array([[room_center[0] - (0.071/2), room_center[0] + (0.071/2)], \n",
    "                  [room_center[1], room_center[1]], \n",
    "                  [room_center[2], room_center[2]]])  # [[x], [y], [z]]\n",
    "    # Setting up room based on rt60\n",
    "    e_absorption, max_order = pra.inverse_sabine(rt60_tgt, room_dim)\n",
    "    room_bf = pra.ShoeBox(room_dim, fs=fs, materials=pra.Material(e_absorption), max_order=max_order)\n",
    "    return room_bf, R, room_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T11:32:47.269204Z",
     "start_time": "2021-11-01T11:32:47.232068Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Main Processing Loop \n",
    "def process_data_dir(top_directory, beamformer = \"mvdr\"):\n",
    "    directory = top_directory + \"audio/\"\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            # Load files\n",
    "            audio_file = os.path.join(directory, filename)\n",
    "            meta_file = os.path.join(top_directory + \"metadata/\", filename[:-3]+\"json\")\n",
    "            fs, signal = wavfile.read(audio_file)\n",
    "            signal = pra.normalize(signal.astype(float))\n",
    "            with open(meta_file) as json_file:\n",
    "                meta_data = json.load(json_file)\n",
    "                \n",
    "            # Setting up room based on rt60\n",
    "            rt60_tgt = float(meta_data['rt60'])\n",
    "            room_bf, R, room_center = get_room(rt60_tgt, fs)\n",
    "            \n",
    "            # Load azimuth and elevation\n",
    "            source_azimuth, source_elevation =  meta_data['source_doa']\n",
    "            noise_azimuth, noise_elevation = meta_data['noise_doa']\n",
    "                \n",
    "            # Putting sources in room\n",
    "            # Assume all sources are 1 meter away from the center (but if SNR is pure speech to noise, \n",
    "            # maybe we can set the distance for each source proportional to the SNR)\n",
    "            r = 1 \n",
    "            # Setup sources for speech and noise \n",
    "            speech_source = [r*np.cos(source_azimuth)*np.cos(source_elevation) + room_center[0],\n",
    "                            r*np.sin(source_azimuth)*np.cos(source_elevation) + room_center[1],\n",
    "                            r*np.sin(source_elevation) + room_center[2]] # [x,y,z]\n",
    "            noise_source = [r*np.cos(noise_azimuth)*np.cos(noise_elevation) + room_center[0],\n",
    "                            r*np.sin(noise_azimuth)*np.cos(noise_elevation) + room_center[1],\n",
    "                            r*np.sin(noise_elevation) + room_center[2]] # [x,y,z]\n",
    "            \n",
    "            # Compute noise variance [Not sure about this bit], is SNR from the source speech?? \n",
    "            # Maybe better use the first 3 seconds for that? \n",
    "            SNR = meta_data['SNR']\n",
    "            if (SNR != None):\n",
    "                SNR = int(SNR)\n",
    "                mono_signal = 0.5 * (signal[:,0] + signal[:,1])\n",
    "                # compute Signal power [not correct if SNR is pure speech to noise instead of noisy speech to noise]\n",
    "                P_s = sp.sum(mono_signal*mono_signal)/mono_signal.size \n",
    "                sigma2_n = P_s / 10**(SNR/10) # compute noise power\n",
    "            else:\n",
    "                sigma2_n = 5e-7 # set small value for noise power if SNR is None\n",
    "\n",
    "            # Here I pass a dummy signal to the source just to simulate. We ignore this signal later\n",
    "            room_bf.add_source(speech_source, delay=0., signal=signal.T[0,:])\n",
    "            room_bf.add_source(noise_source, delay=0, signal=np.zeros_like(signal.T[0,:]))\n",
    "            \n",
    "            # define our beamformer\n",
    "            Lg_t = 0.100                # filter size in seconds\n",
    "            Lg = np.ceil(Lg_t*fs)       # in samples\n",
    "            fft_len = 512\n",
    "            mics = pra.Beamformer(R, room_bf.fs, N=fft_len, Lg=Lg)\n",
    "            room_bf.add_microphone_array(mics)\n",
    "            \n",
    "            # Choose beamformer algorithm\n",
    "            if (beamformer == \"das\"):\n",
    "                mics.rake_delay_and_sum_weights(room_bf.sources[0][:1],room_bf.sources[1][:1])\n",
    "            elif (beamformer == \"mvdr\"):\n",
    "                mics.rake_mvdr_filters(room_bf.sources[0][:1] , room_bf.sources[1][:1] , sigma2_n * \n",
    "                                       np.eye(mics.Lg * mics.M))\n",
    "            elif (beamformer == \"percuptual\"):\n",
    "                mics.rake_perceptual_filters(room_bf.sources[0][0:1] , room_bf.sources[1][0:1] , \n",
    "                                             sigma2_n * np.eye(mics.Lg * mics.M))\n",
    "\n",
    "            # Run simulation\n",
    "            room_bf.compute_rir()\n",
    "            room_bf.simulate()\n",
    "\n",
    "            # Replace microphone signals with the recorded signals in our dataset, i.e. ignoring dummy sources\n",
    "            room_bf.mic_array.record(signal.T, fs)\n",
    "\n",
    "            # Get enhanced signal\n",
    "            beamform_signal = mics.process(FD=False)\n",
    "            beamform_signal = pra.normalize(beamform_signal)\n",
    "            \n",
    "            #Apply denoising \n",
    "            # 1) Spectral Subtractio\n",
    "            denoised_beamform_signal_spectral = apply_spectral_sub(beamform_signal, nfft=512,\n",
    "                                         db_reduc=12, lookback=15, beta=20, alpha=3)\n",
    "            denoised_beamform_signal_spectral = pra.normalize(denoised_beamform_signal_spectral)\n",
    "            # 2) iterative wiener\n",
    "            denoised_beamform_signal_wiener = apply_iterative_wiener(beamform_signal, frame_len=512,\n",
    "                                             lpc_order=20, iterations=2,\n",
    "                                             alpha=0.8, thresh=0.01)\n",
    "            denoised_beamform_signal_wiener = pra.normalize(denoised_beamform_signal_wiener)\n",
    "            \n",
    "            # Apply narrowband speech filtering (does not really seem to make things better, but can save memory)\n",
    "            sos = sps.butter(10, [30, 3000], 'bandpass', fs=fs, output='sos')\n",
    "            # Spectral signal\n",
    "            filtered_denoised_beamform_signal_spectral = sps.sosfilt(sos, denoised_beamform_signal_spectral)\n",
    "            filtered_denoised_beamform_signal_spectral = pra.normalize(filtered_denoised_beamform_signal_spectral)\n",
    "            # Wiener signal\n",
    "            filtered_denoised_beamform_signal_wiener = sps.sosfilt(sos, denoised_beamform_signal_wiener)\n",
    "            filtered_denoised_beamform_signal_wiener = pra.normalize(filtered_denoised_beamform_signal_wiener)\n",
    "\n",
    "            # Downsampling to 6kHz [This is very slow, maybe I can do it with librosa when reading the file later]\n",
    "            # number_of_samples = round(filtered_denoised_beamform_signal.shape[0] * float(6000) / fs)\n",
    "            # downsampled_filtered_denoised_beamform_signal = sps.resample(filtered_denoised_beamform_signal, \n",
    "            #                                                             number_of_samples)\n",
    "\n",
    "            # Saving all version of the signal\n",
    "            # Only beamformed \n",
    "            wavfile.write(top_directory + beamformer + \"/[beamformed]\" + filename, \n",
    "              fs, beamform_signal)\n",
    "            \n",
    "            # Beamformed + Denoise (spectral and wiener)\n",
    "            wavfile.write(top_directory + beamformer + \"_spectral/[spectral_beamformed]\" + filename, \n",
    "              fs, denoised_beamform_signal_spectral)      \n",
    "            wavfile.write(top_directory + beamformer + \"_wiener/[wiener_beamformed]\" + filename, \n",
    "              fs, filtered_denoised_beamform_signal_wiener)\n",
    "            \n",
    "            # Beamformed + Denoise (spectral and wiener) + Speech-Band Filtered\n",
    "            wavfile.write(top_directory + beamformer + \"_spectral_filtered/[filtered_spectral_beamformed]\" + filename, \n",
    "                          fs, filtered_denoised_beamform_signal_spectral)\n",
    "            wavfile.write(top_directory + beamformer + \"_wiener_filtered/[filtered_wiener_beamformed]\" + filename, \n",
    "                          fs, filtered_denoised_beamform_signal_wiener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T15:49:14.744671Z",
     "start_time": "2021-11-01T11:32:48.693379Z"
    }
   },
   "outputs": [],
   "source": [
    "# Process both the train and test data\n",
    "beamforming_methods = [\"das\", \"mvdr\"]\n",
    "#beamforming_methods = [\"das\", \"mvdr\", \"percuptual\"]\n",
    "for beamformer in beamforming_methods:\n",
    "    process_data_dir(TRAIN_DIR, beamformer)\n",
    "    process_data_dir(TEST_DIR, beamformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listen to some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:04:37.335103Z",
     "start_time": "2021-11-01T19:04:37.235743Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load all the  processed  files for a sample audio file\n",
    "TRAIN_DIR = \"/home/karim/Desktop/Sonos_Assignment/vad_train_set/\"\n",
    "sample_file = \"f1_0a4e47f1-184a-473a-a466-64154ff4703f.wav\" #Here is where to choose which file\n",
    "original = TRAIN_DIR + \"audio/\" + sample_file\n",
    "das = TRAIN_DIR + \"das/\" + \"[beamformed]\" + sample_file\n",
    "das_spectral = TRAIN_DIR + \"das_spectral/\" + \"[spectral_beamformed]\" + sample_file\n",
    "das_spectral_filtered = TRAIN_DIR + \"das_spectral_filtered/\" + \"[filtered_spectral_beamformed]\" + sample_file\n",
    "das_wiener = TRAIN_DIR + \"das_wiener/\" + \"[wiener_beamformed]\" + sample_file\n",
    "das_wiener_filtered = TRAIN_DIR + \"das_wiener_filtered/\" + \"[filtered_wiener_beamformed]\" + sample_file\n",
    "mdvr = TRAIN_DIR + \"mvdr/\" + \"[beamformed]\" + sample_file\n",
    "mdv_spectral = TRAIN_DIR + \"mvdr_spectral/\" + \"[spectral_beamformed]\" + sample_file\n",
    "mdv_spectral_filtered = TRAIN_DIR + \"mvdr_spectral_filtered/\" + \"[filtered_spectral_beamformed]\" + sample_file\n",
    "mdvr_wiener = TRAIN_DIR + \"mvdr_wiener/\" + \"[wiener_beamformed]\" + sample_file\n",
    "mdvr_wiener_filtered = TRAIN_DIR + \"mvdr_wiener_filtered/\" + \"[filtered_wiener_beamformed]\" + sample_file\n",
    "\n",
    "fs, signal_original = wavfile.read(original)\n",
    "fs, signal_das = wavfile.read(das)\n",
    "fs, signal_das_spectral = wavfile.read(das_spectral)\n",
    "fs, signal_das_spectral_filtered = wavfile.read(das_spectral_filtered)\n",
    "fs, signal_das_wiener = wavfile.read(das_wiener)\n",
    "fs, signal_das_wiener_filtered = wavfile.read(das_wiener_filtered)\n",
    "fs, signal_mdvr = wavfile.read(mdvr)\n",
    "fs, signal_mdv_spectral = wavfile.read(mdv_spectral)\n",
    "fs, signal_mdv_spectral_filtered = wavfile.read(mdv_spectral_filtered)\n",
    "fs, signal_mdvr_wiener = wavfile.read(mdvr_wiener)\n",
    "fs, signal_mdvr_wiener_filtered = wavfile.read(mdvr_wiener_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:04:47.674364Z",
     "start_time": "2021-11-01T19:04:47.378995Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"The original audio\")\n",
    "IPython.display.Audio(0.5*(signal_original[:,0] + signal_original[:,1]), rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:04:50.056487Z",
     "start_time": "2021-11-01T19:04:49.627588Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"delay-and-sum output\")\n",
    "IPython.display.Audio(signal_das, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:04:52.324927Z",
     "start_time": "2021-11-01T19:04:52.016302Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"delay-and-sum + spectral-subtraction output\")\n",
    "IPython.display.Audio(signal_das_spectral, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:04:55.933949Z",
     "start_time": "2021-11-01T19:04:55.692696Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"delay-and-sum + spectral-subtraction + bandbass filter output\")\n",
    "IPython.display.Audio(signal_das_spectral_filtered, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:04:58.118138Z",
     "start_time": "2021-11-01T19:04:57.846534Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"delay-and-sum + iterative wiener output\")\n",
    "IPython.display.Audio(signal_das_wiener, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:05:01.202715Z",
     "start_time": "2021-11-01T19:05:00.928397Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"delay-and-sum + iterative wiener + bandbass filter output\")\n",
    "IPython.display.Audio(signal_das_wiener_filtered, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mvdr output\")\n",
    "IPython.display.Audio(signal_mdvr, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T18:59:50.174701Z",
     "start_time": "2021-11-01T18:59:50.165934Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"mvdr + spectral-subtraction output\")\n",
    "IPython.display.Audio(signal_mdv_spectral, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mvdr + spectral-subtraction + bandbass filter output\")\n",
    "IPython.display.Audio(signal_mdv_spectral_filtered, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mvdr + iterative wiener output\")\n",
    "IPython.display.Audio(signal_mdvr_wiener, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mvdr + iterative wiener + bandbass filter output\")\n",
    "IPython.display.Audio(signal_mdvr_wiener_filtered, rate=fs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
